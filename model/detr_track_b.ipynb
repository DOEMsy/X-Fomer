{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\A/.cache\\torch\\hub\\facebookresearch_detr_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision.transforms import transforms as T\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from torch import tensor\n",
    "from numpy import random\n",
    "from tqdm import tqdm,trange\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from copy import deepcopy\n",
    "torch.hub.list('facebookresearch/detr:main')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1002942.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in trange(1000):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\A/.cache\\torch\\hub\\facebookresearch_detr_main\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose(\n",
    "    [\n",
    "        T.Resize(800),  # 800\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = torch.hub.load(\"facebookresearch/detr:main\", \"detr_resnet101\", pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "colors = random.randint(255, size=(101, 3))\n",
    "\n",
    "\n",
    "def solve(image, context):\n",
    "\n",
    "    # pred\n",
    "\n",
    "    inp = transform(image).unsqueeze(0)\n",
    "    inp = inp.cuda()\n",
    "    oup = model(inp)\n",
    "\n",
    "    W, H = image.size\n",
    "    def cbox2box(cbox):\n",
    "        x1 = cbox[:, 0] - cbox[:, 2] / 2\n",
    "        y1 = cbox[:, 1] - cbox[:, 3] / 2\n",
    "        x2 = cbox[:, 0] + cbox[:, 2] / 2\n",
    "        y2 = cbox[:, 1] + cbox[:, 3] / 2\n",
    "        box = torch.ones_like(cbox)\n",
    "        box[:, 0] = x1 * W \n",
    "        box[:, 1] = y1 * H \n",
    "        box[:, 2] = x2 * W \n",
    "        box[:, 3] = y2 * H \n",
    "        return box\n",
    "\n",
    "    oup_lgs = oup[\"pred_logits\"].softmax(-1)\n",
    "    labels = oup_lgs[..., :-1].argmax(-1)[0]\n",
    "    scores = oup_lgs[..., :-1].max(-1)[0][0]\n",
    "    scores_not1 = 1 - oup_lgs[..., -1][0]  # 非背景的分数\n",
    "\n",
    "    center_boxes = oup[\"pred_boxes\"][0]  # cbox (中心x, 中心y, box宽，box高)\n",
    "    boxes = cbox2box(center_boxes)\n",
    "\n",
    " \n",
    "\n",
    "    keep_i = 0\n",
    "    if context:\n",
    "        keep_i = range(labels.shape[0])\n",
    "    else:\n",
    "        keep_i = torchvision.ops.nms(boxes, scores, iou_threshold=0.5)\n",
    "        keep_i = keep_i.tolist()\n",
    "\n",
    "    # # 分类型 nms\n",
    "    # keep_i = set()\n",
    "    # for label in range(90):\n",
    "    #     ss = oup_lgs[...,label][0]\n",
    "    #     ks = torchvision.ops.nms(boxes, ss, iou_threshold=0.5)\n",
    "    #     keep_i.update(ks.tolist())\n",
    "\n",
    "    res = []\n",
    "    for i in keep_i:\n",
    "        label = int(labels[i])\n",
    "        score = float(scores[i])\n",
    "        box = boxes[i].tolist()\n",
    "        # if score > 0.5:\n",
    "        #     res.append([label, score, box, i])\n",
    "        if score>0.3 and label in (3, 6, 5, 16):\n",
    "            res.append([label, score, box, i])\n",
    "\n",
    "    \n",
    "    # i -> last_i mapping\n",
    "    def solve_last_i_mapping(res, context):\n",
    "        update_cnt = 0\n",
    "        def IoU(box1, box2):\n",
    "            x1min, y1min, x1max, y1max = box1[0], box1[1], box1[2], box1[3]\n",
    "            if x1min > x1max: x1min,x1max = x1max,x1min\n",
    "            if y1min > y1max: y1min,y1max = y1max,y1min\n",
    "            x2min, y2min, x2max, y2max = box2[0], box2[1], box2[2], box2[3]\n",
    "            if x2min > x2max: x2min,x2max = x2max,x2min\n",
    "            if y2min > y2max: y2min,y2max = y2max,y2min\n",
    "            s1 = (y1max - y1min + 0.1) * (x1max - x1min + 0.1)\n",
    "            s2 = (y2max - y2min + 0.1) * (x2max - x2min + 0.1)\n",
    "            xmin = max(x1min,x2min)\n",
    "            ymin = max(y1min,y2min)\n",
    "            xmax = min(x1max,x2max)\n",
    "            ymax = min(y1max,y2max)\n",
    "            inter_h = max(ymax - ymin + 0.1, 0)\n",
    "            inter_w = max(xmax - xmin + 0.1, 0)\n",
    "            intersection = inter_h * inter_w\n",
    "            union = s1 + s2 - intersection\n",
    "            iou = intersection / union\n",
    "            return iou\n",
    "\n",
    "        iou_matrix = np.zeros((len(res), len(context)), dtype=float)\n",
    "        for i, nowIt in enumerate(res):\n",
    "            for j, lastIt in enumerate(context):\n",
    "                box1 = nowIt[2]\n",
    "                box2 = lastIt[2]\n",
    "                label1 = nowIt[0]\n",
    "                label2 = lastIt[0]\n",
    "                iou_matrix[i][j] = IoU(box1, box2) if label1 == label2 else 0\n",
    "\n",
    "        # print(iou_matrix)\n",
    "\n",
    "        r,l = linear_sum_assignment(iou_matrix, maximize=True)\n",
    "        for i,j in zip(r,l):\n",
    "            if iou_matrix[i][j] > 0:\n",
    "                context[j][2] = res[i][2]\n",
    "                update_cnt += 1\n",
    "\n",
    "        return update_cnt\n",
    "\n",
    "    # 用新的最接近的box更新\n",
    "    update_cnt = 0\n",
    "    if context:\n",
    "        update_cnt = solve_last_i_mapping(res, context)\n",
    "    else:\n",
    "        context = res\n",
    "        update_cnt = res.__len__()\n",
    "    # draw\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.truetype(\"consola.ttf\", 10, encoding=\"unic\")  # 设置字\n",
    "\n",
    "    for it in context:\n",
    "        label = it[0]\n",
    "        score = it[1]\n",
    "        box = it[2]\n",
    "        i = it[3]\n",
    "\n",
    "        # color = tuple(random.randint(255,size=(3)))\n",
    "        color = tuple(colors[i])\n",
    "\n",
    "        draw.rectangle(box, None, color)\n",
    "        # draw.text((box[0], box[1]), \"(%d, %.3f, %d)\"%(label, score, i), color, font)\n",
    "        draw.text((box[0], box[1]), \"%d\" % (i), color, font)\n",
    "\n",
    "    # 更新框少于x%后重新检测\n",
    "    if context.__len__()==0 or update_cnt / context.__len__() < 0.25:\n",
    "        context = None\n",
    "\n",
    "    return image, context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7499 [00:00<?, ?it/s]C:\\Python38\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "100%|█████████▉| 7493/7499 [37:42<00:01,  3.31it/s]\n"
     ]
    }
   ],
   "source": [
    "vedio = cv2.VideoCapture(\"../test/1.mp4\")\n",
    "\n",
    "W = int(vedio.get(3))\n",
    "H = int(vedio.get(4))\n",
    "fps = vedio.get(5)\n",
    "fcout = int(vedio.get(7))\n",
    "\n",
    "# print(W,H,fps,fcout)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "oup_vedio = cv2.VideoWriter(\"../test/oup/1.avi\", fourcc, fps, (W, H), True) \n",
    "\n",
    "context = None\n",
    "\n",
    "for _ in trange(fcout):\n",
    "    rval, frame = vedio.read()\n",
    "    if not rval:\n",
    "        break\n",
    "\n",
    "    image = Image.fromarray(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))  \n",
    "\n",
    "    image, context = solve(image, context)\n",
    "\n",
    "    cvImage = np.array(image)\n",
    "    cvImage = cv2.cvtColor(cvImage,cv2.COLOR_RGB2BGR)\n",
    "    # print(cvImage.shape)\n",
    "    # break\n",
    "    # if _ == 1: break\n",
    "\n",
    "    oup_vedio.write(cvImage)\n",
    "    # cv2.imshow('oup',cvImage)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "vedio.release()\n",
    "oup_vedio.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
